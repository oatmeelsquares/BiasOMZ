{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fb22b97-4299-485f-a3cc-dd4b7fae569b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import openvino as ov\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb7f089-d6a9-448b-afd3-a1b87c4cfb8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reference the below URL for additional guideance if needed\n",
    "# https://github.com/openvinotoolkit/openvino_notebooks/blob/latest/notebooks/openvino-api/openvino-api.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eea13353-2e52-4557-9abb-ee756671be0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fetch `notebook_utils` module\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\n",
    "    url='https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/utils/notebook_utils.py',\n",
    "    filename='notebook_utils.py'\n",
    ")\n",
    "\n",
    "from notebook_utils import download_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b802368-6629-4895-8cac-83187bfa1947",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face-detection-0200 already downloaded to artifacts\n"
     ]
    }
   ],
   "source": [
    "# This Chunk downloads the model if it needs to be downloaded\n",
    "\n",
    "base_artifacts_dir = Path('./artifacts').expanduser()\n",
    "\n",
    "model_name = \"face-detection-0200\"\n",
    "model_xml_name = f'{model_name}.xml'\n",
    "model_bin_name = f'{model_name}.bin'\n",
    "\n",
    "model_xml_path = base_artifacts_dir / model_xml_name\n",
    "\n",
    "base_url = 'https://storage.openvinotoolkit.org/repositories/open_model_zoo/temp/face-detection-0200/FP32/'\n",
    "\n",
    "if not model_xml_path.exists():\n",
    "    download_file(base_url + model_xml_name, model_xml_name, base_artifacts_dir)\n",
    "    download_file(base_url + model_bin_name, model_bin_name, base_artifacts_dir)\n",
    "else:\n",
    "    print(f'{model_name} already downloaded to {base_artifacts_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d18eeef-38eb-4df1-885a-76a519975718",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e17a3673f64ab0bf99faa55f73ee94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Device:', index=1, options=('CPU', 'AUTO'), value='AUTO')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This chunk specifies what device to run the model on i.e. CPU vs GPU\n",
    "import ipywidgets as widgets\n",
    "\n",
    "core = ov.Core()\n",
    "device = widgets.Dropdown(\n",
    "    options=core.available_devices + [\"AUTO\"],\n",
    "    value='AUTO',\n",
    "    description='Device:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41d44ae4-0dcc-44a6-9c3c-9f3fb1045699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This chunk instaniates the model with the open vino objects\n",
    "\n",
    "core = ov.Core()\n",
    "model = core.read_model(model=model_xml_path)\n",
    "compiled_model = core.compile_model(model=model, device_name=device.value)\n",
    "\n",
    "output_layer = compiled_model.output(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31f825a4-b3bd-400b-9d3b-ffab195f9fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input precision: <Type: 'float32'>\n",
      "input shape: [1,3,256,256]\n",
      "output precision: <Type: 'float32'>\n",
      "output shape: [1,1,200,7]\n"
     ]
    }
   ],
   "source": [
    "input_layer = compiled_model.input(0)\n",
    "\n",
    "print(f\"input precision: {input_layer.element_type}\")\n",
    "print(f\"input shape: {input_layer.shape}\")\n",
    "print(f\"output precision: {output_layer.element_type}\")\n",
    "print(f\"output shape: {output_layer.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12cc2ae-dd8e-4cbc-baef-481376f5edc0",
   "metadata": {},
   "source": [
    "The net outputs blob with shape: 1, 1, 200, 7 in the format 1, 1, N, 7, where N is the number of detected bounding boxes. Each detection has the format [image_id, label, conf, x_min, y_min, x_max, y_max], where:\n",
    "\n",
    "    image_id - ID of the image in the batch\n",
    "    label - predicted class ID (0 - face)\n",
    "    conf - confidence for the predicted class\n",
    "    (x_min, y_min) - coordinates of the top left bounding box corner\n",
    "    (x_max, y_max) - coordinates of the bottom right bounding box corner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5e927ae-53ba-4c9d-8016-dc7b9f2039f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 86744/86744 [11:06<00:00, 130.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed images and stored metadata.\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store image metadata\n",
    "image_meta = []\n",
    "\n",
    "# Counter to limit to the first 5 files\n",
    "#file_count = 0\n",
    "\n",
    "image_files = os.listdir('train')\n",
    "\n",
    "# Loop through images in the folder\n",
    "for filename in tqdm(image_files, desc=\"Processing images\"):\n",
    "    \n",
    "    # Stop after processing 5 files\n",
    "    #if file_count >= 10:\n",
    "        #break\n",
    "\n",
    "    # Get the file path\n",
    "    image_path = os.path.join('train', filename)\n",
    "\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Could not read {image_path}\")\n",
    "        continue\n",
    "\n",
    "    # Increment the file count after a successful read\n",
    "    #file_count += 1\n",
    "\n",
    "    # Store the original dimensions\n",
    "    orig_h, orig_w = image.shape[:2]\n",
    "\n",
    "    # Resize to (256, 256) and prepare the input\n",
    "    resized_image = cv2.resize(image, (256, 256))\n",
    "\n",
    "    # Reorder dimensions to (C, H, W) from (H, W, C)\n",
    "    input_image = np.transpose(resized_image, (2, 0, 1))\n",
    "\n",
    "    # Add batch dimension (B=1)\n",
    "    input_image = np.expand_dims(input_image, axis=0)\n",
    "\n",
    "    # Run the model\n",
    "    outputs = compiled_model([input_image])[output_layer]\n",
    "\n",
    "    # Process the output (assuming shape (1, 1, N, 7))\n",
    "    detections = np.squeeze(outputs, axis=(0, 1))\n",
    "    \n",
    "    # Create dummy holding 10392dictionary\n",
    "    image_info = {\"file_path\": image_path, \"confidence\": 0}\n",
    "\n",
    "    # Grab only the first bounding box if available\n",
    "    if len(detections) > 0:\n",
    "        detection = detections[0]\n",
    "        conf = float(detection[2])\n",
    "        if conf > 0.01:  # Confidence threshold\n",
    "            # Bounding box coordinates (relative to the original image size)\n",
    "            x_min = int(detection[3] * orig_w)\n",
    "            y_min = int(detection[4] * orig_h)\n",
    "            x_max = int(detection[5] * orig_w)\n",
    "            y_max = int(detection[6] * orig_h)\n",
    "\n",
    "            # Draw the bounding box on the original image\n",
    "            #cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "            #cv2.putText(image, f\"Conf: {conf:.2f}\", (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            # Update the dictionary with confidence\n",
    "            image_info[\"confidence\"] = conf\n",
    "\n",
    "    # Append the confidence and file path to the metadata list\n",
    "    image_meta.append(image_info)\n",
    "\n",
    "    # Display the result using Matplotlib\n",
    "    #image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    #plt.imshow(image_rgb)\n",
    "    #plt.title(f\"Face Detection - {filename}\")\n",
    "    #plt.axis('off')\n",
    "    #plt.show()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "results_df = pd.DataFrame(image_meta)\n",
    "\n",
    "# Optionally, you can save it to a CSV if needed\n",
    "results_df.to_csv(\"image_metadata.csv\", index=False)\n",
    "print(\"Processed images and stored metadata.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b7a63f4-9872-4c79-8358-a78635d579f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of              file_path  confidence\n",
       "0      train/64277.jpg    0.997335\n",
       "1      train/13135.jpg    0.900043\n",
       "2      train/47394.jpg    0.890959\n",
       "3      train/50091.jpg    0.996324\n",
       "4      train/26594.jpg    0.997323\n",
       "...                ...         ...\n",
       "86739  train/81284.jpg    0.999067\n",
       "86740  train/78930.jpg    0.992692\n",
       "86741  train/31351.jpg    0.997285\n",
       "86742  train/67347.jpg    0.921577\n",
       "86743  train/64566.jpg    0.925131\n",
       "\n",
       "[86744 rows x 2 columns]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
